{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "\n",
        "##### Copyright 2019 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VNhgka4UKNjf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFIqwYGbZ-df"
      },
      "source": [
        "# DDSP Training\n",
        "\n",
        "This notebook demonstrates the process of training a mode through the simple example overfitting a single sample. This notebook gives examples of how to instantiate a model both in python and with gin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S_jXCnwZ2QYW"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "from ddsp.colab.colab_utils import play, specplot, DEFAULT_SAMPLE_RATE\n",
        "import gin\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
        "f32 = ddsp.core.f32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "khYj8yiMDxGL"
      },
      "source": [
        "# Get a Batch of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IzzaWKxVkYms"
      },
      "outputs": [],
      "source": [
        "# Get a single example from NSynth.\n",
        "# Takes a few seconds to load from GCS.\n",
        "data_provider = ddsp.training.data.NSynthTfds(split='test')\n",
        "batch = data_provider.get_batch(batch_size=1, shuffle=False)\n",
        "batch = next(tfds.as_numpy(batch))\n",
        "audio = batch['audio']\n",
        "n_samples = audio.shape[1]\n",
        "\n",
        "specplot(audio[0])\n",
        "play(audio[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bo337pQdDiar"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EWZQXFLehCU0"
      },
      "source": [
        "### Model in python "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HCqXRY1KeX8S"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "preprocessing = ddsp.training.preprocessing\n",
        "encoders = ddsp.training.encoders\n",
        "decoders = ddsp.training.decoders\n",
        "models = ddsp.training.models\n",
        "TIME_STEPS = 1000\n",
        "\n",
        "# Create Neural Networks.\n",
        "preprocessor = preprocessing.DefaultPreprocessor(time_steps=TIME_STEPS)\n",
        "\n",
        "decoder = decoders.RnnFcDecoder(rnn_channels = 256,\n",
        "                                rnn_type = 'gru',\n",
        "                                ch = 256,\n",
        "                                layers_per_stack = 1,\n",
        "                                output_splits = (('amps', 1),\n",
        "                                                 ('harmonic_distribution', 20),\n",
        "                                                 ('noise_magnitudes', 20)))\n",
        "\n",
        "# Create Processors.\n",
        "additive = ddsp.synths.Additive(n_samples=n_samples, \n",
        "                                sample_rate=sample_rate,\n",
        "                                name='additive')\n",
        "\n",
        "# Gradually fade in noise during training for this example.\n",
        "# Not required when training on whole dataset as batch variations help avoid\n",
        "# local minima (only noise and no harmonic components).\n",
        "noise_fade_fn = lambda: ddsp.training.nn.exp_fade(iter_start=0, \n",
        "                                                  iter_end=100, \n",
        "                                                  start_value=1e-5)\n",
        "\n",
        "noise = ddsp.synths.FilteredNoise(window_size=0,\n",
        "                                  noise_fade_fn=noise_fade_fn,\n",
        "                                  name='noise')\n",
        "add = ddsp.processors.Add(name='add')\n",
        "\n",
        "# Create ProcessorGroup.\n",
        "dag = [(additive, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "       (noise, ['noise_magnitudes']),\n",
        "       (add, ['noise/signal', 'additive/signal'])]\n",
        "\n",
        "processor_group = ddsp.processors.ProcessorGroup(dag=dag, name='processor_group')\n",
        "\n",
        "\n",
        "# Loss_functions\n",
        "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
        "                                         mag_weight=1.0,\n",
        "                                         logmag_weight=1.0)\n",
        "\n",
        "# Put it together in a model.\n",
        "model = models.Autoencoder(preprocessor=preprocessor,\n",
        "                           encoder=None,\n",
        "                           decoder=decoder,\n",
        "                           processor_group=processor_group,\n",
        "                           losses=[spectral_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uAZgDMV9hGyp"
      },
      "source": [
        "#### Or model in gin..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1JPmTwQshVya"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "gin_string = \"\"\"\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "\n",
        "# =======\n",
        "# Network\n",
        "# =======\n",
        "\n",
        "# Preprocessor\n",
        "models.Autoencoder.preprocessor = @preprocessing.DefaultPreprocessor()\n",
        "preprocessing.DefaultPreprocessor.time_steps = 1000\n",
        "\n",
        "\n",
        "# Encoder\n",
        "models.Autoencoder.encoder = None\n",
        "\n",
        "# Decoder\n",
        "models.Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
        "decoders.RnnFcDecoder.rnn_channels = 256\n",
        "decoders.RnnFcDecoder.rnn_type = 'gru'\n",
        "decoders.RnnFcDecoder.ch = 256\n",
        "decoders.RnnFcDecoder.layers_per_stack = 1\n",
        "decoders.RnnFcDecoder.output_splits = (('amps', 1),\n",
        "                                       ('harmonic_distribution', 20),\n",
        "                                       ('noise_magnitudes', 20))\n",
        "\n",
        "\n",
        "# =================\n",
        "# Signal Processors\n",
        "# =================\n",
        "\n",
        "# ProcessorGroup\n",
        "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
        "\n",
        "processors.ProcessorGroup.dag = [\n",
        "  (@additive/synths.Additive(),\n",
        "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "  (@noise/synths.FilteredNoise(),\n",
        "    ['noise_magnitudes']),\n",
        "  (@add/processors.Add(),\n",
        "    ['noise/signal', 'additive/signal']),\n",
        "]\n",
        "\n",
        "# Additive Synthesizer\n",
        "additive/synths.Additive.name = 'additive'\n",
        "additive/synths.Additive.n_samples = 64000\n",
        "additive/synths.Additive.sample_rate = 16000\n",
        "additive/synths.Additive.normalize_below_nyquist = True\n",
        "additive/synths.Additive.amp_scale_fn = @core.exp_sigmoid\n",
        "\n",
        "# Filtered Noise Synthesizer\n",
        "noise/synths.FilteredNoise.name = 'noise'\n",
        "noise/synths.FilteredNoise.n_samples = 64000\n",
        "noise/synths.FilteredNoise.window_size = 0\n",
        "noise/synths.FilteredNoise.amp_scale_fn = @core.exp_sigmoid\n",
        "noise/synths.FilteredNoise.noise_fade_fn = @noise_fade/nn.exp_fade\n",
        "\n",
        "noise_fade/nn.exp_fade.iter_start = 0\n",
        "noise_fade/nn.exp_fade.iter_end = 300\n",
        "noise_fade/nn.exp_fade.start_value = 1e-5\n",
        "\n",
        "# Add\n",
        "add/processors.Add.name = 'add'\n",
        "\n",
        "\n",
        "# ======\n",
        "# Losses\n",
        "# ======\n",
        "\n",
        "models.Autoencoder.losses = [\n",
        "    @losses.SpectralLoss(),\n",
        "]\n",
        "losses.SpectralLoss.loss_type = 'L1'\n",
        "losses.SpectralLoss.mag_weight = 1.0\n",
        "losses.SpectralLoss.logmag_weight = 1.0\n",
        "\"\"\"\n",
        "\n",
        "with gin.unlock_config():\n",
        "  gin.parse_config(gin_string)\n",
        "\n",
        "model = ddsp.training.models.Autoencoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSsvL1geY0_S"
      },
      "source": [
        "## Get training op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1lQW604_QWm1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "# Single batch.\n",
        "batch_tf = {k:f32(v) for k, v in batch.items()}\n",
        "\n",
        "# Get model predictions for the batch.\n",
        "outputs = model(batch_tf)\n",
        "loss = outputs['total_loss']\n",
        "train_op = ddsp.training.train_util.get_train_op(loss, \n",
        "                                                 learning_rate=learning_rate)\n",
        "\n",
        "# Setup the session.\n",
        "target = ''\n",
        "target = 'uptc://prod/dragonfish_2x2'  # GOOGLE-INTERNAL\n",
        "sess = tf.Session(target)\n",
        "sess.run(tf.initialize_all_variables())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RFEqt6e1DsqG"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LWdoRIONDxri"
      },
      "outputs": [],
      "source": [
        "for i in range(300):\n",
        "  _, loss_ = sess.run([train_op, loss])\n",
        "  print('i: {}\\tLoss: {}'.format(i, loss_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QKFGwMbXY4PJ"
      },
      "source": [
        "# Make Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2cj220vSF8_Y"
      },
      "source": [
        "# Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mDU_FysURm_Z"
      },
      "outputs": [],
      "source": [
        "# Run a batch of predictions.\n",
        "start_time = time.time()\n",
        "predictions = sess.run(outputs)\n",
        "end_time = time.time()\n",
        "infer_time = end_time - start_time\n",
        "print('Prediction took %.1f seconds' % infer_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DVhoLzV-ZYav"
      },
      "outputs": [],
      "source": [
        "# Predictions\n",
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "k = 0\n",
        "\n",
        "audio = predictions['audio'][k]\n",
        "audio_gen = predictions['audio_gen'][k]\n",
        "amps = predictions['additive']['controls']['amplitudes'][k]\n",
        "harmonic_distribution = predictions['additive']['controls']['harmonic_distribution'][k]\n",
        "f0_hz = predictions['f0_hz'][k]\n",
        "loudness = predictions['loudness'][k]\n",
        "\n",
        "play(audio)\n",
        "play(audio_gen)\n",
        "\n",
        "specplot(audio)\n",
        "plt.title('Audio')\n",
        "specplot(audio_gen)\n",
        "plt.title('Audio Synth')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "ax[0].semilogy(amps)\n",
        "ax[0].set_xlabel('Amps')\n",
        "ax[0].set_ylim(1e-5, 2)\n",
        "ax[1].plot(loudness)\n",
        "ax[1].set_xlabel('loudness')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "ax[0].plot(harmonic_distribution)\n",
        "ax[0].set_title('Harmonic Distribution')\n",
        "ax[1].plot(f0_hz)\n",
        "ax[1].set_title('F0_Hz')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hMqWDc_m6rUC",
        "ZFIqwYGbZ-df",
        "khYj8yiMDxGL",
        "Bo337pQdDiar",
        "EWZQXFLehCU0",
        "uAZgDMV9hGyp",
        "zSsvL1geY0_S",
        "RFEqt6e1DsqG",
        "QKFGwMbXY4PJ",
        "2cj220vSF8_Y"
      ],
      "last_runtime": {
        "build_target": "//third_party/py/ddsp/colab:colab_notebook",
        "kind": "shared"
      },
      "name": "3_training.ipynb",
      "provenance": [
        {
          "file_id": "/piper/depot/google3/learning/brain/research/magenta/models/ddsp/rt_nsynth/colab/train.ipynb",
          "timestamp": 1567721111335
        },
        {
          "file_id": "/piper/depot/google3/learning/brain/research/magenta/models/ddsp/rt_nsynth/colab/train.ipynb?workspaceId=hanoih:ddsp_abstract_2::citc",
          "timestamp": 1567213145529
        },
        {
          "file_id": "/piper/depot/google3/learning/brain/research/magenta/models/ddsp/rt_nsynth/colab/train.ipynb",
          "timestamp": 1566587144673
        },
        {
          "file_id": "/piper/depot/google3/learning/brain/research/magenta/models/ddsp/rt_nsynth/colab/predict.ipynb?workspaceId=jesseengel:ddsp::citc",
          "timestamp": 1563490713452
        },
        {
          "file_id": "1qon7pbO51PTvyVzTk9UnwAuELL9ruNVi",
          "timestamp": 1560799547131
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
